## 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ğŸ¬
- ì‚¬ì§„ì—ì„œ ê°ì²´ë§Œ ì¶”ì¶œí•˜ê¸°
- ì¶”ì¶œëœ ë°ì´í„° ë¶„ë¥˜ë° ë°ì´í„° ì…‹ ì‘ì—…

ë”¥ëŸ¬ë‹ : YOLO / ì‚¬ìš©ì ì§€ì • : grabCut 

## 2. ìƒ‰ìƒ ì•Œê³ ë¦¬ì¦˜ ğŸ›©ï¸
- ìƒ‰ìƒ ë“±ë¡ (í‘œì¤€, ì‚¬ì§„ê³¼ ì´ë¯¸ì§€)
- ìƒ‰ìƒì„ íŒë‹¨í•  ì‚¬ì§„ ì…ë ¥ (ì „ì²˜ë¦¬x)
- ìƒ‰ìƒì„ íŒë‹¨í•  ì‚¬ì§„ ì…ë ¥ (grabCut ì ìš© ì´ë¯¸ì§€)
<br>


# ëª¨ë¸ë§ ê³„íš :star:

### ëª©í‘œ  
- ê°ì²´ íƒì§€ (YOLO-spp ì¬í•™ìŠµ)  
- íƒì§€ëœ ì‹ë¬¼ ì˜ì—­ì— ëŒ€í•´ ì‹ë¬¼ì˜ ì—¬ëŸ¬ íŠ¹ì„± ë° í’ˆì¢… ì˜ˆì¸¡ (ìˆ˜ì¹˜í™”)

### 1ë‹¨ê³„ : ë°ì´í„°ì…‹ ì¤€ë¹„ âœ”ï¸
- ì´ë¯¸ì§€ ë°ì´í„°ì˜ ì €ì¥ í˜•íƒœ
<pre><code>/dataset
    /species_1
        - img1.jpg
        - img2.jpg
        ...
    /species_2
        - img1.jpg
        - img2.jpg
        ...
    ...
</code></pre>
- íŠ¹ì„± ë ˆì´ë¸” ë°ì´í„°
<pre><code>/dataset/crack_labels.csv</code></pre>
![í™”ë©´ ìº¡ì²˜ 2024-07-01 141804](https://github.com/lko9911/Algorithms_total/assets/160494158/29bc8ea7-bc19-4e75-bb50-d5da28bd9d66)

### 2ë‹¨ê³„ : YOLO ëª¨ë¸ ì¬í•™ìŠµ âœ”ï¸
ì¤€ë¹„ë¬¼ : 'cfg', 'weights', 'obj.names', 'obj.data' ì–´ë…¸í…Œì´ì…˜ íŒŒì¼

- YOLO ì„¤ì • íŒŒì¼ ìˆ˜ì •
<pre><code>convolutional]
filters=21  # (classes + 5) * 3

[yolo]
classes=2</code></pre>

- YOLO ëª¨ë¸ í•™ìŠµ
<pre><code>./darknet detector train data/obj.data cfg/yolov3.cfg yolov3.conv.74
</code></pre>

### 3ë‹¨ê³„ : í’ˆì¢… ì˜ˆì¸¡ ëª¨ë¸ (CNN) âœ”ï¸
- ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
<pre><code>import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# íŠ¹ì„± ë ˆì´ë¸” ë¡œë“œ
labels_df = pd.read_csv('dataset/crack_labels.csv')

# ì´ë¯¸ì§€ ê²½ë¡œì™€ íŠ¹ì„± ë ˆì´ë¸”ì„ ë¶„ë¦¬
image_paths = labels_df['image_path'].values
crack_levels = labels_df['crack_level'].values
color_intensities = labels_df['color_intensity'].values
leaf_sizes = labels_df['leaf_size'].values

# ë°ì´í„° ì „ì²˜ë¦¬
datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = datagen.flow_from_directory(
    'dataset',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training')

validation_generator = datagen.flow_from_directory(
    'dataset',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation')
</code></pre>
- ë°ì´í„° í•™ìŠµ (CNNëª¨ë¸ ì‚¬ìš©)
<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.models import Model

# ì…ë ¥ ë ˆì´ì–´
input_layer = Input(shape=(224, 224, 3))

# í•©ì„±ê³± ë ˆì´ì–´
x = Conv2D(32, (3, 3), activation='relu')(input_layer)
x = MaxPooling2D((2, 2))(x)
x = Conv2D(64, (3, 3), activation='relu')(x)
x = MaxPooling2D((2, 2))(x)
x = Conv2D(128, (3, 3), activation='relu')(x)
x = MaxPooling2D((2, 2))(x)
x = Flatten()(x)

# í’ˆì¢… ì˜ˆì¸¡ ì¶œë ¥ ë ˆì´ì–´
num_species_classes = len(train_generator.class_indices)
output_species = Dense(num_species_classes, activation='softmax', name='species_output')(x)

# íŠ¹ì„± ì˜ˆì¸¡ ì¶œë ¥ ë ˆì´ì–´ 1: ê»ì§ˆ ê°ˆë¼ì§ ì •ë„
num_crack_levels = len(set(crack_levels))
output_crack = Dense(num_crack_levels, activation='softmax', name='crack_output')(x)

# íŠ¹ì„± ì˜ˆì¸¡ ì¶œë ¥ ë ˆì´ì–´ 2: ì±„ë„
output_color = Dense(1, activation='linear', name='color_output')(x)

# íŠ¹ì„± ì˜ˆì¸¡ ì¶œë ¥ ë ˆì´ì–´ 3: ì í¬ê¸°
output_leaf = Dense(1, activation='linear', name='leaf_output')(x)

# ëª¨ë¸ ì •ì˜
model = Model(inputs=input_layer, outputs=[output_species, output_crack, output_color, output_leaf])

# ëª¨ë¸ ì»´íŒŒì¼
model.compile(optimizer='adam',
              loss={'species_output': 'categorical_crossentropy',
                    'crack_output': 'categorical_crossentropy',
                    'color_output': 'mean_squared_error',
                    'leaf_output': 'mean_squared_error'},
              metrics={'species_output': 'accuracy', 'crack_output': 'accuracy', 'color_output': 'mae', 'leaf_output': 'mae'})

model.summary()

# ëª¨ë¸ í•™ìŠµ
history = model.fit(
    train_generator,
    epochs=10,
    validation_data=validation_generator
) 
</code></pre>

### 4ë‹¨ê³„ : YOLO + íŠ¹ì„± ë¶„ì„ ê²°í•© âœ”ï¸
- íƒì§€ëœ ì‹ë¬¼ ì˜ì—­ì— ëŒ€í•´ íŠ¹ì„± ë¶„ì„ì„ ìˆ˜í–‰
<pre><code>import cv2 as cv
import numpy as np
from tensorflow.keras.preprocessing import image

# YOLO ëª¨ë¸ ë¡œë“œ
net = cv.dnn.readNet("yolov3.weights", "yolov3.cfg")
with open("obj.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# ì´ë¯¸ì§€ ë¡œë“œ
image_path = 'path_to_your_image.png'
img = cv.imread(image_path)
height, width, channels = img.shape

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
blob = cv.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
net.setInput(blob)
outs = net.forward(net.getUnconnectedOutLayersNames())

# ë¬¼ì²´ ê²€ì¶œ
class_ids = []
confidences = []
boxes = []

for out in outs:
    for detection in out:
        scores = detection[5:]
        class_id = np.argmax(scores)
        confidence = scores[class_id]
        if confidence > 0.5:
            center_x = int(detection[0] * width)
            center_y = int(detection[1] * height)
            w = int(detection[2] * width)
            h = int(detection[3] * height)
            x = int(center_x - w / 2)
            y = int(center_y - h / 2)
            boxes.append([x, y, w, h])
            confidences.append(float(confidence))
            class_ids.append(class_id)

# Non-maximum suppression
indexes = cv.dnn.NMSBoxes(boxes, confidences, score_threshold=0.5, nms_threshold=0.4)

# ê° ê°ì²´ì— ëŒ€í•´ íŠ¹ì„± ì˜ˆì¸¡
for i in range(len(boxes)):
    if i in indexes:
        x, y, w, h = boxes[i]
        roi = img[y:y+h, x:x+w]
        roi_resized = cv.resize(roi, (224, 224))
        img_array = image.img_to_array(roi_resized)
        img_array = np.expand_dims(img_array, axis=0) / 255.0

        # íŠ¹ì„± ì˜ˆì¸¡
        species_prediction, crack_prediction = model.predict(img_array)
        species_class = np.argmax(species_prediction, axis=1)[0]
        crack_level = np.argmax(crack_prediction, axis=1)[0]

        # ê²°ê³¼ í‘œì‹œ
        label = f"Species: {species_class}, Crack Level: {crack_level}"
        color = (0, 255, 0)
        cv.rectangle(img, (x, y), (x + w, y + h), color, 2)
        cv.putText(img, label, (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

# ê²°ê³¼ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
cv.imwrite('predicted_objects.jpg', img)

# ê²°ê³¼ ì´ë¯¸ì§€ ì¶œë ¥
cv.imshow('Object detection and prediction', img)
cv.waitKey(0)
cv.destroyAllWindows()</code></pre>

### 5ë‹¨ê³„ : ëª¨ë¸ í‰ê°€ âœ”ï¸
- í˜¼ëˆí–‰ë ¬ ë¦¬í¬íŠ¸
- k êµì°¨ ê²€ì¦
- ROC ê³¡ì„ 

### ë°ì´í„° ì…ë ¥ 
<pre><code>from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np

# í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
model_path = 'path_to_your_trained_model.h5'

# ëª¨ë¸ ë¡œë“œ
model = load_model(model_path)

# ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
image_path = 'path_to_your_image.jpg'

# ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
img = image.load_img(image_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0) / 255.0  # ëª¨ë¸ì— ë§ëŠ” ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”

# ì˜ˆì¸¡ ìˆ˜í–‰
predictions = model.predict(img_array)

# ì˜ˆì¸¡ ê²°ê³¼ í•´ì„
species_prediction = np.argmax(predictions[0])
crack_level_prediction = np.argmax(predictions[1])
color_intensity_prediction = predictions[2]
leaf_size_prediction = predictions[3]

print(f'Species Prediction: {species_prediction}')
print(f'Crack Level Prediction: {crack_level_prediction}')
print(f'Color Intensity Prediction: {color_intensity_prediction}')
print(f'Leaf Size Prediction: {leaf_size_prediction}')</code></pre>
